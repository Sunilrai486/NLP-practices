{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import  MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import svm\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "print(len(news.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(classifier, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 48)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(f\"Classifier testing accuracy: {classifier.score(X_test, y_test)}\")\n",
    "    \n",
    "    print(f\"Classifier training accuracy: {classifier.score(X_train, y_train)}\")\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1 = Pipeline([(\"vectorizer\", TfidfVectorizer()),\n",
    "                    (\"classifier\", MultinomialNB())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier testing accuracy: 0.8535653650254669\n",
      "Classifier training accuracy: 0.9254987972265459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(trial1, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial2 = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=stopwords.words('english'))),\n",
    "                    (\"classifier\", MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier testing accuracy: 0.8828522920203735\n",
      "Classifier training accuracy: 0.9472194707796802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(trial2, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial3 = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=stopwords.words('english'))), \n",
    "                   (\"classifier\", MultinomialNB(alpha=0.05))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier testing accuracy: 0.91553480475382\n",
      "Classifier training accuracy: 0.9898118013301259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('classifier', MultinomialNB(alpha=0.05))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(trial3, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail4 = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=stopwords.words(\"english\") + list(string.punctuation), min_df = 5)),\n",
    "                    (\"classifier\", svm.LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier testing accuracy: 0.9276315789473685\n",
      "Classifier training accuracy: 0.998584972406962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(min_df=5,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(trail4, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train5 = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=stopwords.words(\"english\") + list(string.punctuation), min_df = 5)),\n",
    "                    (\"classifier\", RandomForestClassifier(random_state = 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier testing accuracy: 0.8535653650254669\n",
      "Classifier training accuracy: 0.999929248620348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(min_df=5,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(train5, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train6 = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=stopwords.words(\"english\") + list(string.punctuation), min_df = 5)),\n",
    "                    (\"classifier\", xgb.XGBClassifier(objective='multi:softmax', num_class=3, seed=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier testing accuracy: 0.8486842105263158\n",
      "Classifier training accuracy: 0.999929248620348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(min_df=5,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=None, booster=...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_class=3, num_parallel_tree=None,\n",
       "                               objective='multi:softmax', ...))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(train6, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.6/232.6 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textract\n",
      "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
      "Collecting pdfminer.six==20191110\n",
      "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting python-pptx~=0.6.18\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "     ---------------------------------------- 10.1/10.1 MB 7.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting xlrd~=1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "     -------------------------------------- 103.3/103.3 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting beautifulsoup4~=4.8.0\n",
      "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.9/106.9 kB 6.0 MB/s eta 0:00:00\n",
      "Collecting docx2txt~=0.8\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting extract-msg<=0.29.*\n",
      "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
      "     ---------------------------------------- 69.0/69.0 kB 3.9 MB/s eta 0:00:00\n",
      "Collecting six~=1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting SpeechRecognition~=3.8.1\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "     ---------------------------------------- 32.8/32.8 MB 6.7 MB/s eta 0:00:00\n",
      "Collecting argcomplete~=1.10.0\n",
      "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.18.0-cp35-abi3-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from beautifulsoup4~=4.8.0->textract) (2.3.1)\n",
      "Requirement already satisfied: tzlocal>=2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (5.0.1)\n",
      "Collecting imapclient==2.1.0\n",
      "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 74.0/74.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: olefile>=0.46 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
      "Collecting compressed-rtf>=1.0.6\n",
      "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ebcdic>=1.1.1\n",
      "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
      "     -------------------------------------- 128.5/128.5 kB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (4.9.1)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (9.2.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (3.0.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\acer\\anaconda3\\lib\\site-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (2023.3)\n",
      "Building wheels for collected packages: docx2txt, python-pptx, compressed-rtf\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3979 sha256=c43b178f00c2440bee2b66ce5552c049740c3383cf9b74f9bafafd22e945227f\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\40\\75\\01\\e6c444034338bde9c7947d3467807f889123465c2371e77418\n",
      "  Building wheel for python-pptx (setup.py): started\n",
      "  Building wheel for python-pptx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=6d1be2150406210c5984f833d954b947e5e2b52f2d3e023a6d422e412d114360\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\0e\\4a\\ed\\9653bc799915f52dce3f04d14946fbd85cce9c3cdedc9cfa71\n",
      "  Building wheel for compressed-rtf (setup.py): started\n",
      "  Building wheel for compressed-rtf (setup.py): finished with status 'done'\n",
      "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=1a2c7c550503d4781a9915386b126d81221ab207efaf8fc80e695a708aa6dc03\n",
      "  Stored in directory: c:\\users\\acer\\appdata\\local\\pip\\cache\\wheels\\e4\\67\\e4\\ba2159853bdd0fe99330aa1e384915108143a5370686ea446f\n",
      "Successfully built docx2txt python-pptx compressed-rtf\n",
      "Installing collected packages: SpeechRecognition, ebcdic, docx2txt, compressed-rtf, chardet, argcomplete, xlrd, six, python-pptx, pycryptodome, beautifulsoup4, pdfminer.six, imapclient, extract-msg, textract\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 2.0.1\n",
      "    Uninstalling xlrd-2.0.1:\n",
      "      Successfully uninstalled xlrd-2.0.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.11.1\n",
      "    Uninstalling beautifulsoup4-4.11.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\n",
      "  Attempting uninstall: pdfminer.six\n",
      "    Found existing installation: pdfminer.six 20221105\n",
      "    Uninstalling pdfminer.six-20221105:\n",
      "      Successfully uninstalled pdfminer.six-20221105\n",
      "Successfully installed SpeechRecognition-3.8.1 argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 pdfminer.six-20191110 pycryptodome-3.18.0 python-pptx-0.6.21 six-1.12.0 textract-1.6.5 xlrd-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\n",
      "anaconda-client 1.11.0 requires six>=1.15.0, but you have six 1.12.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObj = open('In-class_Assignment-3 (1).pdf', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(pdfReader.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObj = pdfReader.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Class -Assigment 3:   \n",
      "Statistic Analysis  \n",
      "Assignment Type:  Individual lab work  \n",
      "Weight : 5% \n",
      "Time : In Class/ …../  \n",
      "Tasks :  \n",
      "In this assignment, you will continue working on your selected data source from the previous \n",
      "assignment and present data set statistics  and practice data visualization.  \n",
      "For each selected column compute : \n",
      "1. Range  \n",
      "2. Interquartile  range  (IQR)  \n",
      "3. Median  \n",
      "4. Mean  \n",
      "5. Mode  \n",
      "6. 1st and 3rd  quartile s \n",
      "7. Sample variance and sample standard deviation  \n",
      "8. Find Outliers   \n",
      "Draw the following  diagrams:  \n",
      "1. Box Plot  \n",
      "2. Sea-born Simplot  \n",
      "3. Linear regression  \n",
      "4. HeatMap  \n",
      "Perform statistical analysis and present  results  in graphical format . \n",
      "Deliverables:  \n",
      "a) Submit a professional r eport  including at least:   \n",
      "a. Explain  the steps/formulas that have been used for calculation process  \n"
     ]
    }
   ],
   "source": [
    "print(pageObj.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdfFileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Class -Assigment 3:   \n",
      "Statistic Analysis  \n",
      "Assignment Type:  Individual lab work  \n",
      "Weight : 5% \n",
      "Time : In Class/ …../  \n",
      "Tasks :  \n",
      "In this assignment, you will continue working on your selected data source from the previous \n",
      "assignment and present data set statistics  and practice data visualization.  \n",
      "For each selected column compute : \n",
      "1. Range  \n",
      "2. Interquartile  range  (IQR)  \n",
      "3. Median  \n",
      "4. Mean  \n",
      "5. Mode  \n",
      "6. 1st and 3rd  quartile s \n",
      "7. Sample variance and sample standard deviation  \n",
      "8. Find Outliers   \n",
      "Draw the following  diagrams:  \n",
      "1. Box Plot  \n",
      "2. Sea-born Simplot  \n",
      "3. Linear regression  \n",
      "4. HeatMap  \n",
      "Perform statistical analysis and present  results  in graphical format . \n",
      "Deliverables:  \n",
      "a) Submit a professional r eport  including at least:   \n",
      "a. Explain  the steps/formulas that have been used for calculation process  b. Detailed explanations of your solution including snippets of your source code.  \n",
      "c. Describe results from statistical  analysis and diagrams . \n",
      "d. Your experience reflection   \n",
      "b) Python Jupiter notebook  \n",
      "a. Comments in code  \n",
      "b. Fully working solution  \n",
      " \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "text = \"\"\n",
    "\n",
    "while c< len(pdfReader.pages):\n",
    "    pageObj = pdfReader.pages[c]\n",
    "    c+=1\n",
    "    text += pageObj.extract_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Class -Assigment 3:   \n",
      "In-Class -Assigment 3:\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"\"\n",
    "pageObj = pdfReader.pages[0]\n",
    "text += pageObj.extract_text()\n",
    "\n",
    "print(text.split('\\n')[0])\n",
    "\n",
    "print(re.findall(r\".*:\", text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Type': '/Page', '/Parent': IndirectObject(2, 0, 1965144482768), '/Resources': {'/Font': {'/F1': IndirectObject(5, 0, 1965144482768), '/F2': IndirectObject(12, 0, 1965144482768), '/F3': IndirectObject(14, 0, 1965144482768), '/F4': IndirectObject(19, 0, 1965144482768), '/F5': IndirectObject(21, 0, 1965144482768)}, '/ExtGState': {'/GS10': IndirectObject(10, 0, 1965144482768), '/GS11': IndirectObject(11, 0, 1965144482768)}, '/ProcSet': ['/PDF', '/Text', '/ImageB', '/ImageC', '/ImageI']}, '/MediaBox': [0, 0, 612, 792], '/Contents': IndirectObject(4, 0, 1965144482768), '/Group': {'/Type': '/Group', '/S': '/Transparency', '/CS': '/DeviceRGB'}, '/Tabs': '/S', '/StructParents': 0}\n",
      "In-Class -Assigment 3:   \n",
      "Statistic Analysis  \n",
      "Assignment Type:  Individual lab work  \n",
      "Weight : 5% \n",
      "Time : In Class/ …../  \n",
      "Tasks :  \n",
      "In this assignment, you will continue working on your selected data source from the previous \n",
      "assignment and present data set statistics  and practice data visualization.  \n",
      "For each selected column compute : \n",
      "1. Range  \n",
      "2. Interquartile  range  (IQR)  \n",
      "3. Median  \n",
      "4. Mean  \n",
      "5. Mode  \n",
      "6. 1st and 3rd  quartile s \n",
      "7. Sample variance and sample standard deviation  \n",
      "8. Find Outliers   \n",
      "Draw the following  diagrams:  \n",
      "1. Box Plot  \n",
      "2. Sea-born Simplot  \n",
      "3. Linear regression  \n",
      "4. HeatMap  \n",
      "Perform statistical analysis and present  results  in graphical format . \n",
      "Deliverables:  \n",
      "a) Submit a professional r eport  including at least:   \n",
      "a. Explain  the steps/formulas that have been used for calculation process  In-Class -Assigment 3:   \n",
      "Statistic Analysis  \n",
      "Assignment Type:  Individual lab work  \n",
      "Weight : 5% \n",
      "Time : In Class/ …../  \n",
      "Tasks :  \n",
      "In this assignment, you will continue working on your selected data source from the previous \n",
      "assignment and present data set statistics  and practice data visualization.  \n",
      "For each selected column compute : \n",
      "1. Range  \n",
      "2. Interquartile  range  (IQR)  \n",
      "3. Median  \n",
      "4. Mean  \n",
      "5. Mode  \n",
      "6. 1st and 3rd  quartile s \n",
      "7. Sample variance and sample standard deviation  \n",
      "8. Find Outliers   \n",
      "Draw the following  diagrams:  \n",
      "1. Box Plot  \n",
      "2. Sea-born Simplot  \n",
      "3. Linear regression  \n",
      "4. HeatMap  \n",
      "Perform statistical analysis and present  results  in graphical format . \n",
      "Deliverables:  \n",
      "a) Submit a professional r eport  including at least:   \n",
      "a. Explain  the steps/formulas that have been used for calculation process  \n"
     ]
    }
   ],
   "source": [
    "page_one = pdfReader.pages[0]\n",
    "text += pageObj.extract_text()\n",
    "print(page_one)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_document_writer = PyPDF2.PdfWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Type': '/Page',\n",
       " '/Resources': {'/Font': {'/F1': {'/Type': '/Font',\n",
       "    '/Subtype': '/Type0',\n",
       "    '/BaseFont': '/TimesNewRomanPS-BoldMT',\n",
       "    '/Encoding': '/Identity-H',\n",
       "    '/DescendantFonts': [IndirectObject(7, 0, 1965130618864)],\n",
       "    '/ToUnicode': {'/Filter': '/FlateDecode'}},\n",
       "   '/F2': {'/Type': '/Font',\n",
       "    '/Subtype': '/TrueType',\n",
       "    '/Name': '/F2',\n",
       "    '/BaseFont': '/TimesNewRomanPS-BoldMT',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/TimesNewRomanPS-BoldMT',\n",
       "     '/Flags': 32,\n",
       "     '/ItalicAngle': 0,\n",
       "     '/Ascent': 891,\n",
       "     '/Descent': -216,\n",
       "     '/CapHeight': 677,\n",
       "     '/AvgWidth': 427,\n",
       "     '/MaxWidth': 2558,\n",
       "     '/FontWeight': 700,\n",
       "     '/XHeight': 250,\n",
       "     '/Leading': 42,\n",
       "     '/StemV': 42,\n",
       "     '/FontBBox': [-558, -216, 2000, 677]},\n",
       "    '/FirstChar': 32,\n",
       "    '/LastChar': 32,\n",
       "    '/Widths': [250]},\n",
       "   '/F3': {'/Type': '/Font',\n",
       "    '/Subtype': '/Type0',\n",
       "    '/BaseFont': '/TimesNewRomanPSMT',\n",
       "    '/Encoding': '/Identity-H',\n",
       "    '/DescendantFonts': [IndirectObject(18, 0, 1965130618864)],\n",
       "    '/ToUnicode': {'/Filter': '/FlateDecode'}},\n",
       "   '/F4': {'/Type': '/Font',\n",
       "    '/Subtype': '/TrueType',\n",
       "    '/Name': '/F4',\n",
       "    '/BaseFont': '/TimesNewRomanPSMT',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/TimesNewRomanPSMT',\n",
       "     '/Flags': 32,\n",
       "     '/ItalicAngle': 0,\n",
       "     '/Ascent': 891,\n",
       "     '/Descent': -216,\n",
       "     '/CapHeight': 693,\n",
       "     '/AvgWidth': 401,\n",
       "     '/MaxWidth': 2614,\n",
       "     '/FontWeight': 400,\n",
       "     '/XHeight': 250,\n",
       "     '/Leading': 42,\n",
       "     '/StemV': 40,\n",
       "     '/FontBBox': [-568, -216, 2046, 693]},\n",
       "    '/FirstChar': 32,\n",
       "    '/LastChar': 32,\n",
       "    '/Widths': [250]},\n",
       "   '/F5': {'/Type': '/Font',\n",
       "    '/Subtype': '/TrueType',\n",
       "    '/Name': '/F5',\n",
       "    '/BaseFont': '/ArialMT',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/ArialMT',\n",
       "     '/Flags': 32,\n",
       "     '/ItalicAngle': 0,\n",
       "     '/Ascent': 905,\n",
       "     '/Descent': -210,\n",
       "     '/CapHeight': 728,\n",
       "     '/AvgWidth': 441,\n",
       "     '/MaxWidth': 2665,\n",
       "     '/FontWeight': 400,\n",
       "     '/XHeight': 250,\n",
       "     '/Leading': 33,\n",
       "     '/StemV': 44,\n",
       "     '/FontBBox': [-665, -210, 2000, 728]},\n",
       "    '/FirstChar': 32,\n",
       "    '/LastChar': 32,\n",
       "    '/Widths': [278]}},\n",
       "  '/ExtGState': {'/GS10': {'/Type': '/ExtGState', '/BM': '/Normal', '/ca': 1},\n",
       "   '/GS11': {'/Type': '/ExtGState', '/BM': '/Normal', '/CA': 1}},\n",
       "  '/ProcSet': ['/PDF', '/Text', '/ImageB', '/ImageC', '/ImageI']},\n",
       " '/MediaBox': [0, 0, 612, 792],\n",
       " '/Contents': {'/Filter': '/FlateDecode'},\n",
       " '/Group': {'/Type': '/Group', '/S': '/Transparency', '/CS': '/DeviceRGB'},\n",
       " '/Tabs': '/S',\n",
       " '/Parent': {'/Type': '/Pages',\n",
       "  '/Count': 1,\n",
       "  '/Kids': [IndirectObject(4, 0, 1965130618864)]}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_document_writer.add_page(page_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_output = open(\"new_file_2.pdf\", 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, <_io.BufferedWriter name='new_file_2.pdf'>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_document_writer.write(pdf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObj.close()\n",
    "pdf_document_writer.close()\n",
    "pdf_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
